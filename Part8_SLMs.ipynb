{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM7U0uzQeyoRXws8JHgS/nE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vedantpople4/LLM/blob/main/Part8_SLMs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVB944ivwikm",
        "outputId": "f7b79e0a-4891-4ced-f014-87d2d1013c63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qO_Zxox_xDaK",
        "outputId": "b97922cc-ef26-4490-a134-ca063d742ee0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.util import ngrams\n",
        "from collections import defaultdict\n",
        "import random\n",
        "\n",
        "# Download required NLTK data\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Sample text for training\n",
        "text = \"\"\"Small language models are computational models that can respond to and generate natural language.\n",
        "They are built with fewer parameters and simpler neural architectures, allowing for faster training and reduced\n",
        "energy consumption. SLMs break text into word embeddings which are processed by a transformer using an encoder.\n",
        "A decoder then produces a unique response to the text.\"\"\"\n",
        "\n",
        "# Tokenize the text\n",
        "tokens = word_tokenize(text.lower())\n",
        "\n",
        "# Create bigrams\n",
        "bigrams = list(ngrams(tokens, 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QCnZiopwx8R",
        "outputId": "7074cfa8-c2e5-4727-bebb-223b6e0eb851"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dictionary to store bigram frequencies\n",
        "bigram_model = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "# Count bigram frequencies\n",
        "for bigram in bigrams:\n",
        "    bigram_model[bigram[0]][bigram[1]] += 1\n",
        "\n",
        "# Function to generate text\n",
        "def generate_text(start_word, num_words):\n",
        "    current_word = start_word\n",
        "    generated_text = [current_word]\n",
        "\n",
        "    for _ in range(num_words - 1):\n",
        "        if current_word in bigram_model:\n",
        "            next_word = random.choices(\n",
        "                list(bigram_model[current_word].keys()),\n",
        "                weights=list(bigram_model[current_word].values())\n",
        "            )[0]\n",
        "            generated_text.append(next_word)\n",
        "            current_word = next_word\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    return ' '.join(generated_text)\n",
        "\n",
        "# Generate text\n",
        "print(generate_text('small', 10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WyvBi5cw9i2",
        "outputId": "e5bd7221-1189-4889-b9ca-980630ed6a39"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "small language models are built with fewer parameters and reduced\n"
          ]
        }
      ]
    }
  ]
}