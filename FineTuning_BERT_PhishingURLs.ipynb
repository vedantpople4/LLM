{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vedantpople4/LLM/blob/main/FineTuning_BERT_PhishingURLs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets evaluate transformers[sentencepiece]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "hZ0ve1p0gU5x",
        "outputId": "fdaf05ae-9791-40f5-a3ba-6567b06f27e6"
      },
      "id": "hZ0ve1p0gU5x",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.2.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.3)\n",
            "Requirement already satisfied: transformers[sentencepiece] in /usr/local/lib/python3.11/dist-packages (4.47.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.11)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.27.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]) (0.5.2)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]) (0.2.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]) (4.25.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80e7473f-9077-45fa-9bc7-7df1ac01258c",
      "metadata": {
        "id": "80e7473f-9077-45fa-9bc7-7df1ac01258c"
      },
      "source": [
        "### imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "a32b5c69-b8b2-4807-b6c5-d5ed3d237b7e",
      "metadata": {
        "id": "a32b5c69-b8b2-4807-b6c5-d5ed3d237b7e"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "\n",
        "import evaluate\n",
        "import numpy as np\n",
        "from transformers import DataCollatorWithPadding"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c799a68-36aa-4ecc-8c57-2becf92b38e2",
      "metadata": {
        "id": "2c799a68-36aa-4ecc-8c57-2becf92b38e2"
      },
      "source": [
        "### load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "f4fbd278-3ace-49cb-9765-5dbed896d5ae",
      "metadata": {
        "id": "f4fbd278-3ace-49cb-9765-5dbed896d5ae"
      },
      "outputs": [],
      "source": [
        "dataset_dict = load_dataset(\"shawhin/phishing-site-classification\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "edb6b85e-9b43-44cc-a335-e415635d7c31",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edb6b85e-9b43-44cc-a335-e415635d7c31",
        "outputId": "81d9041a-8495-4feb-eaf5-cf9fd7c09f3d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'labels'],\n",
              "        num_rows: 2100\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['text', 'labels'],\n",
              "        num_rows: 450\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'labels'],\n",
              "        num_rows: 450\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "dataset_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2bf82a01",
      "metadata": {
        "id": "2bf82a01"
      },
      "source": [
        "### Train Teacher Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "ec0311bd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec0311bd",
        "outputId": "c6f2e394-c61d-4360-e215-7b0e70b1d20a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Load model directly\n",
        "model_path = \"google-bert/bert-base-uncased\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "\n",
        "id2label = {0: \"Safe\", 1: \"Not Safe\"}\n",
        "label2id = {\"Safe\": 0, \"Not Safe\": 1}\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path,\n",
        "                                                           num_labels=2,\n",
        "                                                           id2label=id2label,\n",
        "                                                           label2id=label2id,)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "826084b6",
      "metadata": {
        "id": "826084b6"
      },
      "source": [
        "#### Freeze base model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "03aa44f2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03aa44f2",
        "outputId": "47d3fd8a-3c92-4bad-be6f-f05df1b6d750"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert.embeddings.word_embeddings.weight True\n",
            "bert.embeddings.position_embeddings.weight True\n",
            "bert.embeddings.token_type_embeddings.weight True\n",
            "bert.embeddings.LayerNorm.weight True\n",
            "bert.embeddings.LayerNorm.bias True\n",
            "bert.encoder.layer.0.attention.self.query.weight True\n",
            "bert.encoder.layer.0.attention.self.query.bias True\n",
            "bert.encoder.layer.0.attention.self.key.weight True\n",
            "bert.encoder.layer.0.attention.self.key.bias True\n",
            "bert.encoder.layer.0.attention.self.value.weight True\n",
            "bert.encoder.layer.0.attention.self.value.bias True\n",
            "bert.encoder.layer.0.attention.output.dense.weight True\n",
            "bert.encoder.layer.0.attention.output.dense.bias True\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight True\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias True\n",
            "bert.encoder.layer.0.intermediate.dense.weight True\n",
            "bert.encoder.layer.0.intermediate.dense.bias True\n",
            "bert.encoder.layer.0.output.dense.weight True\n",
            "bert.encoder.layer.0.output.dense.bias True\n",
            "bert.encoder.layer.0.output.LayerNorm.weight True\n",
            "bert.encoder.layer.0.output.LayerNorm.bias True\n",
            "bert.encoder.layer.1.attention.self.query.weight True\n",
            "bert.encoder.layer.1.attention.self.query.bias True\n",
            "bert.encoder.layer.1.attention.self.key.weight True\n",
            "bert.encoder.layer.1.attention.self.key.bias True\n",
            "bert.encoder.layer.1.attention.self.value.weight True\n",
            "bert.encoder.layer.1.attention.self.value.bias True\n",
            "bert.encoder.layer.1.attention.output.dense.weight True\n",
            "bert.encoder.layer.1.attention.output.dense.bias True\n",
            "bert.encoder.layer.1.attention.output.LayerNorm.weight True\n",
            "bert.encoder.layer.1.attention.output.LayerNorm.bias True\n",
            "bert.encoder.layer.1.intermediate.dense.weight True\n",
            "bert.encoder.layer.1.intermediate.dense.bias True\n",
            "bert.encoder.layer.1.output.dense.weight True\n",
            "bert.encoder.layer.1.output.dense.bias True\n",
            "bert.encoder.layer.1.output.LayerNorm.weight True\n",
            "bert.encoder.layer.1.output.LayerNorm.bias True\n",
            "bert.encoder.layer.2.attention.self.query.weight True\n",
            "bert.encoder.layer.2.attention.self.query.bias True\n",
            "bert.encoder.layer.2.attention.self.key.weight True\n",
            "bert.encoder.layer.2.attention.self.key.bias True\n",
            "bert.encoder.layer.2.attention.self.value.weight True\n",
            "bert.encoder.layer.2.attention.self.value.bias True\n",
            "bert.encoder.layer.2.attention.output.dense.weight True\n",
            "bert.encoder.layer.2.attention.output.dense.bias True\n",
            "bert.encoder.layer.2.attention.output.LayerNorm.weight True\n",
            "bert.encoder.layer.2.attention.output.LayerNorm.bias True\n",
            "bert.encoder.layer.2.intermediate.dense.weight True\n",
            "bert.encoder.layer.2.intermediate.dense.bias True\n",
            "bert.encoder.layer.2.output.dense.weight True\n",
            "bert.encoder.layer.2.output.dense.bias True\n",
            "bert.encoder.layer.2.output.LayerNorm.weight True\n",
            "bert.encoder.layer.2.output.LayerNorm.bias True\n",
            "bert.encoder.layer.3.attention.self.query.weight True\n",
            "bert.encoder.layer.3.attention.self.query.bias True\n",
            "bert.encoder.layer.3.attention.self.key.weight True\n",
            "bert.encoder.layer.3.attention.self.key.bias True\n",
            "bert.encoder.layer.3.attention.self.value.weight True\n",
            "bert.encoder.layer.3.attention.self.value.bias True\n",
            "bert.encoder.layer.3.attention.output.dense.weight True\n",
            "bert.encoder.layer.3.attention.output.dense.bias True\n",
            "bert.encoder.layer.3.attention.output.LayerNorm.weight True\n",
            "bert.encoder.layer.3.attention.output.LayerNorm.bias True\n",
            "bert.encoder.layer.3.intermediate.dense.weight True\n",
            "bert.encoder.layer.3.intermediate.dense.bias True\n",
            "bert.encoder.layer.3.output.dense.weight True\n",
            "bert.encoder.layer.3.output.dense.bias True\n",
            "bert.encoder.layer.3.output.LayerNorm.weight True\n",
            "bert.encoder.layer.3.output.LayerNorm.bias True\n",
            "bert.encoder.layer.4.attention.self.query.weight True\n",
            "bert.encoder.layer.4.attention.self.query.bias True\n",
            "bert.encoder.layer.4.attention.self.key.weight True\n",
            "bert.encoder.layer.4.attention.self.key.bias True\n",
            "bert.encoder.layer.4.attention.self.value.weight True\n",
            "bert.encoder.layer.4.attention.self.value.bias True\n",
            "bert.encoder.layer.4.attention.output.dense.weight True\n",
            "bert.encoder.layer.4.attention.output.dense.bias True\n",
            "bert.encoder.layer.4.attention.output.LayerNorm.weight True\n",
            "bert.encoder.layer.4.attention.output.LayerNorm.bias True\n",
            "bert.encoder.layer.4.intermediate.dense.weight True\n",
            "bert.encoder.layer.4.intermediate.dense.bias True\n",
            "bert.encoder.layer.4.output.dense.weight True\n",
            "bert.encoder.layer.4.output.dense.bias True\n",
            "bert.encoder.layer.4.output.LayerNorm.weight True\n",
            "bert.encoder.layer.4.output.LayerNorm.bias True\n",
            "bert.encoder.layer.5.attention.self.query.weight True\n",
            "bert.encoder.layer.5.attention.self.query.bias True\n",
            "bert.encoder.layer.5.attention.self.key.weight True\n",
            "bert.encoder.layer.5.attention.self.key.bias True\n",
            "bert.encoder.layer.5.attention.self.value.weight True\n",
            "bert.encoder.layer.5.attention.self.value.bias True\n",
            "bert.encoder.layer.5.attention.output.dense.weight True\n",
            "bert.encoder.layer.5.attention.output.dense.bias True\n",
            "bert.encoder.layer.5.attention.output.LayerNorm.weight True\n",
            "bert.encoder.layer.5.attention.output.LayerNorm.bias True\n",
            "bert.encoder.layer.5.intermediate.dense.weight True\n",
            "bert.encoder.layer.5.intermediate.dense.bias True\n",
            "bert.encoder.layer.5.output.dense.weight True\n",
            "bert.encoder.layer.5.output.dense.bias True\n",
            "bert.encoder.layer.5.output.LayerNorm.weight True\n",
            "bert.encoder.layer.5.output.LayerNorm.bias True\n",
            "bert.encoder.layer.6.attention.self.query.weight True\n",
            "bert.encoder.layer.6.attention.self.query.bias True\n",
            "bert.encoder.layer.6.attention.self.key.weight True\n",
            "bert.encoder.layer.6.attention.self.key.bias True\n",
            "bert.encoder.layer.6.attention.self.value.weight True\n",
            "bert.encoder.layer.6.attention.self.value.bias True\n",
            "bert.encoder.layer.6.attention.output.dense.weight True\n",
            "bert.encoder.layer.6.attention.output.dense.bias True\n",
            "bert.encoder.layer.6.attention.output.LayerNorm.weight True\n",
            "bert.encoder.layer.6.attention.output.LayerNorm.bias True\n",
            "bert.encoder.layer.6.intermediate.dense.weight True\n",
            "bert.encoder.layer.6.intermediate.dense.bias True\n",
            "bert.encoder.layer.6.output.dense.weight True\n",
            "bert.encoder.layer.6.output.dense.bias True\n",
            "bert.encoder.layer.6.output.LayerNorm.weight True\n",
            "bert.encoder.layer.6.output.LayerNorm.bias True\n",
            "bert.encoder.layer.7.attention.self.query.weight True\n",
            "bert.encoder.layer.7.attention.self.query.bias True\n",
            "bert.encoder.layer.7.attention.self.key.weight True\n",
            "bert.encoder.layer.7.attention.self.key.bias True\n",
            "bert.encoder.layer.7.attention.self.value.weight True\n",
            "bert.encoder.layer.7.attention.self.value.bias True\n",
            "bert.encoder.layer.7.attention.output.dense.weight True\n",
            "bert.encoder.layer.7.attention.output.dense.bias True\n",
            "bert.encoder.layer.7.attention.output.LayerNorm.weight True\n",
            "bert.encoder.layer.7.attention.output.LayerNorm.bias True\n",
            "bert.encoder.layer.7.intermediate.dense.weight True\n",
            "bert.encoder.layer.7.intermediate.dense.bias True\n",
            "bert.encoder.layer.7.output.dense.weight True\n",
            "bert.encoder.layer.7.output.dense.bias True\n",
            "bert.encoder.layer.7.output.LayerNorm.weight True\n",
            "bert.encoder.layer.7.output.LayerNorm.bias True\n",
            "bert.encoder.layer.8.attention.self.query.weight True\n",
            "bert.encoder.layer.8.attention.self.query.bias True\n",
            "bert.encoder.layer.8.attention.self.key.weight True\n",
            "bert.encoder.layer.8.attention.self.key.bias True\n",
            "bert.encoder.layer.8.attention.self.value.weight True\n",
            "bert.encoder.layer.8.attention.self.value.bias True\n",
            "bert.encoder.layer.8.attention.output.dense.weight True\n",
            "bert.encoder.layer.8.attention.output.dense.bias True\n",
            "bert.encoder.layer.8.attention.output.LayerNorm.weight True\n",
            "bert.encoder.layer.8.attention.output.LayerNorm.bias True\n",
            "bert.encoder.layer.8.intermediate.dense.weight True\n",
            "bert.encoder.layer.8.intermediate.dense.bias True\n",
            "bert.encoder.layer.8.output.dense.weight True\n",
            "bert.encoder.layer.8.output.dense.bias True\n",
            "bert.encoder.layer.8.output.LayerNorm.weight True\n",
            "bert.encoder.layer.8.output.LayerNorm.bias True\n",
            "bert.encoder.layer.9.attention.self.query.weight True\n",
            "bert.encoder.layer.9.attention.self.query.bias True\n",
            "bert.encoder.layer.9.attention.self.key.weight True\n",
            "bert.encoder.layer.9.attention.self.key.bias True\n",
            "bert.encoder.layer.9.attention.self.value.weight True\n",
            "bert.encoder.layer.9.attention.self.value.bias True\n",
            "bert.encoder.layer.9.attention.output.dense.weight True\n",
            "bert.encoder.layer.9.attention.output.dense.bias True\n",
            "bert.encoder.layer.9.attention.output.LayerNorm.weight True\n",
            "bert.encoder.layer.9.attention.output.LayerNorm.bias True\n",
            "bert.encoder.layer.9.intermediate.dense.weight True\n",
            "bert.encoder.layer.9.intermediate.dense.bias True\n",
            "bert.encoder.layer.9.output.dense.weight True\n",
            "bert.encoder.layer.9.output.dense.bias True\n",
            "bert.encoder.layer.9.output.LayerNorm.weight True\n",
            "bert.encoder.layer.9.output.LayerNorm.bias True\n",
            "bert.encoder.layer.10.attention.self.query.weight True\n",
            "bert.encoder.layer.10.attention.self.query.bias True\n",
            "bert.encoder.layer.10.attention.self.key.weight True\n",
            "bert.encoder.layer.10.attention.self.key.bias True\n",
            "bert.encoder.layer.10.attention.self.value.weight True\n",
            "bert.encoder.layer.10.attention.self.value.bias True\n",
            "bert.encoder.layer.10.attention.output.dense.weight True\n",
            "bert.encoder.layer.10.attention.output.dense.bias True\n",
            "bert.encoder.layer.10.attention.output.LayerNorm.weight True\n",
            "bert.encoder.layer.10.attention.output.LayerNorm.bias True\n",
            "bert.encoder.layer.10.intermediate.dense.weight True\n",
            "bert.encoder.layer.10.intermediate.dense.bias True\n",
            "bert.encoder.layer.10.output.dense.weight True\n",
            "bert.encoder.layer.10.output.dense.bias True\n",
            "bert.encoder.layer.10.output.LayerNorm.weight True\n",
            "bert.encoder.layer.10.output.LayerNorm.bias True\n",
            "bert.encoder.layer.11.attention.self.query.weight True\n",
            "bert.encoder.layer.11.attention.self.query.bias True\n",
            "bert.encoder.layer.11.attention.self.key.weight True\n",
            "bert.encoder.layer.11.attention.self.key.bias True\n",
            "bert.encoder.layer.11.attention.self.value.weight True\n",
            "bert.encoder.layer.11.attention.self.value.bias True\n",
            "bert.encoder.layer.11.attention.output.dense.weight True\n",
            "bert.encoder.layer.11.attention.output.dense.bias True\n",
            "bert.encoder.layer.11.attention.output.LayerNorm.weight True\n",
            "bert.encoder.layer.11.attention.output.LayerNorm.bias True\n",
            "bert.encoder.layer.11.intermediate.dense.weight True\n",
            "bert.encoder.layer.11.intermediate.dense.bias True\n",
            "bert.encoder.layer.11.output.dense.weight True\n",
            "bert.encoder.layer.11.output.dense.bias True\n",
            "bert.encoder.layer.11.output.LayerNorm.weight True\n",
            "bert.encoder.layer.11.output.LayerNorm.bias True\n",
            "bert.pooler.dense.weight True\n",
            "bert.pooler.dense.bias True\n",
            "classifier.weight True\n",
            "classifier.bias True\n"
          ]
        }
      ],
      "source": [
        "# print layers\n",
        "for name, param in model.named_parameters():\n",
        "   print(name, param.requires_grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "9b569296",
      "metadata": {
        "id": "9b569296"
      },
      "outputs": [],
      "source": [
        "# freeze base model parameters\n",
        "for name, param in model.base_model.named_parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# unfreeze base model pooling layers\n",
        "for name, param in model.base_model.named_parameters():\n",
        "    if \"pooler\" in name:\n",
        "        param.requires_grad = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "161d7c59",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "161d7c59",
        "outputId": "7f74c1a1-1710-41b3-c897-35bc96aa2187"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert.embeddings.word_embeddings.weight False\n",
            "bert.embeddings.position_embeddings.weight False\n",
            "bert.embeddings.token_type_embeddings.weight False\n",
            "bert.embeddings.LayerNorm.weight False\n",
            "bert.embeddings.LayerNorm.bias False\n",
            "bert.encoder.layer.0.attention.self.query.weight False\n",
            "bert.encoder.layer.0.attention.self.query.bias False\n",
            "bert.encoder.layer.0.attention.self.key.weight False\n",
            "bert.encoder.layer.0.attention.self.key.bias False\n",
            "bert.encoder.layer.0.attention.self.value.weight False\n",
            "bert.encoder.layer.0.attention.self.value.bias False\n",
            "bert.encoder.layer.0.attention.output.dense.weight False\n",
            "bert.encoder.layer.0.attention.output.dense.bias False\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight False\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias False\n",
            "bert.encoder.layer.0.intermediate.dense.weight False\n",
            "bert.encoder.layer.0.intermediate.dense.bias False\n",
            "bert.encoder.layer.0.output.dense.weight False\n",
            "bert.encoder.layer.0.output.dense.bias False\n",
            "bert.encoder.layer.0.output.LayerNorm.weight False\n",
            "bert.encoder.layer.0.output.LayerNorm.bias False\n",
            "bert.encoder.layer.1.attention.self.query.weight False\n",
            "bert.encoder.layer.1.attention.self.query.bias False\n",
            "bert.encoder.layer.1.attention.self.key.weight False\n",
            "bert.encoder.layer.1.attention.self.key.bias False\n",
            "bert.encoder.layer.1.attention.self.value.weight False\n",
            "bert.encoder.layer.1.attention.self.value.bias False\n",
            "bert.encoder.layer.1.attention.output.dense.weight False\n",
            "bert.encoder.layer.1.attention.output.dense.bias False\n",
            "bert.encoder.layer.1.attention.output.LayerNorm.weight False\n",
            "bert.encoder.layer.1.attention.output.LayerNorm.bias False\n",
            "bert.encoder.layer.1.intermediate.dense.weight False\n",
            "bert.encoder.layer.1.intermediate.dense.bias False\n",
            "bert.encoder.layer.1.output.dense.weight False\n",
            "bert.encoder.layer.1.output.dense.bias False\n",
            "bert.encoder.layer.1.output.LayerNorm.weight False\n",
            "bert.encoder.layer.1.output.LayerNorm.bias False\n",
            "bert.encoder.layer.2.attention.self.query.weight False\n",
            "bert.encoder.layer.2.attention.self.query.bias False\n",
            "bert.encoder.layer.2.attention.self.key.weight False\n",
            "bert.encoder.layer.2.attention.self.key.bias False\n",
            "bert.encoder.layer.2.attention.self.value.weight False\n",
            "bert.encoder.layer.2.attention.self.value.bias False\n",
            "bert.encoder.layer.2.attention.output.dense.weight False\n",
            "bert.encoder.layer.2.attention.output.dense.bias False\n",
            "bert.encoder.layer.2.attention.output.LayerNorm.weight False\n",
            "bert.encoder.layer.2.attention.output.LayerNorm.bias False\n",
            "bert.encoder.layer.2.intermediate.dense.weight False\n",
            "bert.encoder.layer.2.intermediate.dense.bias False\n",
            "bert.encoder.layer.2.output.dense.weight False\n",
            "bert.encoder.layer.2.output.dense.bias False\n",
            "bert.encoder.layer.2.output.LayerNorm.weight False\n",
            "bert.encoder.layer.2.output.LayerNorm.bias False\n",
            "bert.encoder.layer.3.attention.self.query.weight False\n",
            "bert.encoder.layer.3.attention.self.query.bias False\n",
            "bert.encoder.layer.3.attention.self.key.weight False\n",
            "bert.encoder.layer.3.attention.self.key.bias False\n",
            "bert.encoder.layer.3.attention.self.value.weight False\n",
            "bert.encoder.layer.3.attention.self.value.bias False\n",
            "bert.encoder.layer.3.attention.output.dense.weight False\n",
            "bert.encoder.layer.3.attention.output.dense.bias False\n",
            "bert.encoder.layer.3.attention.output.LayerNorm.weight False\n",
            "bert.encoder.layer.3.attention.output.LayerNorm.bias False\n",
            "bert.encoder.layer.3.intermediate.dense.weight False\n",
            "bert.encoder.layer.3.intermediate.dense.bias False\n",
            "bert.encoder.layer.3.output.dense.weight False\n",
            "bert.encoder.layer.3.output.dense.bias False\n",
            "bert.encoder.layer.3.output.LayerNorm.weight False\n",
            "bert.encoder.layer.3.output.LayerNorm.bias False\n",
            "bert.encoder.layer.4.attention.self.query.weight False\n",
            "bert.encoder.layer.4.attention.self.query.bias False\n",
            "bert.encoder.layer.4.attention.self.key.weight False\n",
            "bert.encoder.layer.4.attention.self.key.bias False\n",
            "bert.encoder.layer.4.attention.self.value.weight False\n",
            "bert.encoder.layer.4.attention.self.value.bias False\n",
            "bert.encoder.layer.4.attention.output.dense.weight False\n",
            "bert.encoder.layer.4.attention.output.dense.bias False\n",
            "bert.encoder.layer.4.attention.output.LayerNorm.weight False\n",
            "bert.encoder.layer.4.attention.output.LayerNorm.bias False\n",
            "bert.encoder.layer.4.intermediate.dense.weight False\n",
            "bert.encoder.layer.4.intermediate.dense.bias False\n",
            "bert.encoder.layer.4.output.dense.weight False\n",
            "bert.encoder.layer.4.output.dense.bias False\n",
            "bert.encoder.layer.4.output.LayerNorm.weight False\n",
            "bert.encoder.layer.4.output.LayerNorm.bias False\n",
            "bert.encoder.layer.5.attention.self.query.weight False\n",
            "bert.encoder.layer.5.attention.self.query.bias False\n",
            "bert.encoder.layer.5.attention.self.key.weight False\n",
            "bert.encoder.layer.5.attention.self.key.bias False\n",
            "bert.encoder.layer.5.attention.self.value.weight False\n",
            "bert.encoder.layer.5.attention.self.value.bias False\n",
            "bert.encoder.layer.5.attention.output.dense.weight False\n",
            "bert.encoder.layer.5.attention.output.dense.bias False\n",
            "bert.encoder.layer.5.attention.output.LayerNorm.weight False\n",
            "bert.encoder.layer.5.attention.output.LayerNorm.bias False\n",
            "bert.encoder.layer.5.intermediate.dense.weight False\n",
            "bert.encoder.layer.5.intermediate.dense.bias False\n",
            "bert.encoder.layer.5.output.dense.weight False\n",
            "bert.encoder.layer.5.output.dense.bias False\n",
            "bert.encoder.layer.5.output.LayerNorm.weight False\n",
            "bert.encoder.layer.5.output.LayerNorm.bias False\n",
            "bert.encoder.layer.6.attention.self.query.weight False\n",
            "bert.encoder.layer.6.attention.self.query.bias False\n",
            "bert.encoder.layer.6.attention.self.key.weight False\n",
            "bert.encoder.layer.6.attention.self.key.bias False\n",
            "bert.encoder.layer.6.attention.self.value.weight False\n",
            "bert.encoder.layer.6.attention.self.value.bias False\n",
            "bert.encoder.layer.6.attention.output.dense.weight False\n",
            "bert.encoder.layer.6.attention.output.dense.bias False\n",
            "bert.encoder.layer.6.attention.output.LayerNorm.weight False\n",
            "bert.encoder.layer.6.attention.output.LayerNorm.bias False\n",
            "bert.encoder.layer.6.intermediate.dense.weight False\n",
            "bert.encoder.layer.6.intermediate.dense.bias False\n",
            "bert.encoder.layer.6.output.dense.weight False\n",
            "bert.encoder.layer.6.output.dense.bias False\n",
            "bert.encoder.layer.6.output.LayerNorm.weight False\n",
            "bert.encoder.layer.6.output.LayerNorm.bias False\n",
            "bert.encoder.layer.7.attention.self.query.weight False\n",
            "bert.encoder.layer.7.attention.self.query.bias False\n",
            "bert.encoder.layer.7.attention.self.key.weight False\n",
            "bert.encoder.layer.7.attention.self.key.bias False\n",
            "bert.encoder.layer.7.attention.self.value.weight False\n",
            "bert.encoder.layer.7.attention.self.value.bias False\n",
            "bert.encoder.layer.7.attention.output.dense.weight False\n",
            "bert.encoder.layer.7.attention.output.dense.bias False\n",
            "bert.encoder.layer.7.attention.output.LayerNorm.weight False\n",
            "bert.encoder.layer.7.attention.output.LayerNorm.bias False\n",
            "bert.encoder.layer.7.intermediate.dense.weight False\n",
            "bert.encoder.layer.7.intermediate.dense.bias False\n",
            "bert.encoder.layer.7.output.dense.weight False\n",
            "bert.encoder.layer.7.output.dense.bias False\n",
            "bert.encoder.layer.7.output.LayerNorm.weight False\n",
            "bert.encoder.layer.7.output.LayerNorm.bias False\n",
            "bert.encoder.layer.8.attention.self.query.weight False\n",
            "bert.encoder.layer.8.attention.self.query.bias False\n",
            "bert.encoder.layer.8.attention.self.key.weight False\n",
            "bert.encoder.layer.8.attention.self.key.bias False\n",
            "bert.encoder.layer.8.attention.self.value.weight False\n",
            "bert.encoder.layer.8.attention.self.value.bias False\n",
            "bert.encoder.layer.8.attention.output.dense.weight False\n",
            "bert.encoder.layer.8.attention.output.dense.bias False\n",
            "bert.encoder.layer.8.attention.output.LayerNorm.weight False\n",
            "bert.encoder.layer.8.attention.output.LayerNorm.bias False\n",
            "bert.encoder.layer.8.intermediate.dense.weight False\n",
            "bert.encoder.layer.8.intermediate.dense.bias False\n",
            "bert.encoder.layer.8.output.dense.weight False\n",
            "bert.encoder.layer.8.output.dense.bias False\n",
            "bert.encoder.layer.8.output.LayerNorm.weight False\n",
            "bert.encoder.layer.8.output.LayerNorm.bias False\n",
            "bert.encoder.layer.9.attention.self.query.weight False\n",
            "bert.encoder.layer.9.attention.self.query.bias False\n",
            "bert.encoder.layer.9.attention.self.key.weight False\n",
            "bert.encoder.layer.9.attention.self.key.bias False\n",
            "bert.encoder.layer.9.attention.self.value.weight False\n",
            "bert.encoder.layer.9.attention.self.value.bias False\n",
            "bert.encoder.layer.9.attention.output.dense.weight False\n",
            "bert.encoder.layer.9.attention.output.dense.bias False\n",
            "bert.encoder.layer.9.attention.output.LayerNorm.weight False\n",
            "bert.encoder.layer.9.attention.output.LayerNorm.bias False\n",
            "bert.encoder.layer.9.intermediate.dense.weight False\n",
            "bert.encoder.layer.9.intermediate.dense.bias False\n",
            "bert.encoder.layer.9.output.dense.weight False\n",
            "bert.encoder.layer.9.output.dense.bias False\n",
            "bert.encoder.layer.9.output.LayerNorm.weight False\n",
            "bert.encoder.layer.9.output.LayerNorm.bias False\n",
            "bert.encoder.layer.10.attention.self.query.weight False\n",
            "bert.encoder.layer.10.attention.self.query.bias False\n",
            "bert.encoder.layer.10.attention.self.key.weight False\n",
            "bert.encoder.layer.10.attention.self.key.bias False\n",
            "bert.encoder.layer.10.attention.self.value.weight False\n",
            "bert.encoder.layer.10.attention.self.value.bias False\n",
            "bert.encoder.layer.10.attention.output.dense.weight False\n",
            "bert.encoder.layer.10.attention.output.dense.bias False\n",
            "bert.encoder.layer.10.attention.output.LayerNorm.weight False\n",
            "bert.encoder.layer.10.attention.output.LayerNorm.bias False\n",
            "bert.encoder.layer.10.intermediate.dense.weight False\n",
            "bert.encoder.layer.10.intermediate.dense.bias False\n",
            "bert.encoder.layer.10.output.dense.weight False\n",
            "bert.encoder.layer.10.output.dense.bias False\n",
            "bert.encoder.layer.10.output.LayerNorm.weight False\n",
            "bert.encoder.layer.10.output.LayerNorm.bias False\n",
            "bert.encoder.layer.11.attention.self.query.weight False\n",
            "bert.encoder.layer.11.attention.self.query.bias False\n",
            "bert.encoder.layer.11.attention.self.key.weight False\n",
            "bert.encoder.layer.11.attention.self.key.bias False\n",
            "bert.encoder.layer.11.attention.self.value.weight False\n",
            "bert.encoder.layer.11.attention.self.value.bias False\n",
            "bert.encoder.layer.11.attention.output.dense.weight False\n",
            "bert.encoder.layer.11.attention.output.dense.bias False\n",
            "bert.encoder.layer.11.attention.output.LayerNorm.weight False\n",
            "bert.encoder.layer.11.attention.output.LayerNorm.bias False\n",
            "bert.encoder.layer.11.intermediate.dense.weight False\n",
            "bert.encoder.layer.11.intermediate.dense.bias False\n",
            "bert.encoder.layer.11.output.dense.weight False\n",
            "bert.encoder.layer.11.output.dense.bias False\n",
            "bert.encoder.layer.11.output.LayerNorm.weight False\n",
            "bert.encoder.layer.11.output.LayerNorm.bias False\n",
            "bert.pooler.dense.weight True\n",
            "bert.pooler.dense.bias True\n",
            "classifier.weight True\n",
            "classifier.bias True\n"
          ]
        }
      ],
      "source": [
        "# print layers\n",
        "for name, param in model.named_parameters():\n",
        "   print(name, param.requires_grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d2e421a",
      "metadata": {
        "id": "5d2e421a"
      },
      "source": [
        "#### Preprocess text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "cf0dc1e1",
      "metadata": {
        "id": "cf0dc1e1"
      },
      "outputs": [],
      "source": [
        "# define text preprocessing\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples[\"text\"], truncation=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "b42616c7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "8c5b6addc8de445e8622702e50972d21",
            "5936b77da88c4fefa0af273625670d1c",
            "eb78fca1614a40cc8dbbed6866de8ef1",
            "9412e28ad64d42c59df8d03fd9b654b4",
            "aa67cf721f454cdea31f3ff9808e3414",
            "e44e081ac7c9420790b487121e2b35f7",
            "64cf21145cf94c1b87a9a2f4ab82f92f",
            "c80d97bd202e4c96bcaca8b7e81d18d5",
            "0f23040bdd594fdcb4b06794296fd0f3",
            "7dd42acbf05f43e4b17e9bb3fecf30fe",
            "6583ed437f684ad38a1d2d8039ab736d"
          ]
        },
        "id": "b42616c7",
        "outputId": "f10ecd80-69e2-4275-c800-296daa6513b8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/450 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8c5b6addc8de445e8622702e50972d21"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# tokenize all datasetse\n",
        "tokenized_data = dataset_dict.map(preprocess_function, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "04a04a18",
      "metadata": {
        "id": "04a04a18"
      },
      "outputs": [],
      "source": [
        "# create data collator\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e2ce8c7",
      "metadata": {
        "id": "7e2ce8c7"
      },
      "source": [
        "#### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "16b12c6d",
      "metadata": {
        "id": "16b12c6d"
      },
      "outputs": [],
      "source": [
        "# load metrics\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "auc_score = evaluate.load(\"roc_auc\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    # get predictions\n",
        "    predictions, labels = eval_pred\n",
        "\n",
        "    # apply softmax to get probabilities\n",
        "    probabilities = np.exp(predictions) / np.exp(predictions).sum(-1, keepdims=True)\n",
        "    # use probabilities of the positive class for ROC AUC\n",
        "    positive_class_probs = probabilities[:, 1]\n",
        "    # compute auc\n",
        "    auc = np.round(auc_score.compute(prediction_scores=positive_class_probs, references=labels)['roc_auc'],3)\n",
        "\n",
        "    # predict most probable class\n",
        "    predicted_classes = np.argmax(predictions, axis=1)\n",
        "    # compute accuracy\n",
        "    acc = np.round(accuracy.compute(predictions=predicted_classes, references=labels)['accuracy'],3)\n",
        "\n",
        "    return {\"Accuracy\": acc, \"AUC\": auc}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68613386",
      "metadata": {
        "id": "68613386"
      },
      "source": [
        "#### Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "579f1230",
      "metadata": {
        "id": "579f1230"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "lr = 2e-4\n",
        "batch_size = 8\n",
        "num_epochs = 10\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"bert-phishing-classifier_teacher\",\n",
        "    learning_rate=lr,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=num_epochs,\n",
        "    logging_strategy=\"epoch\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "7c4df3d5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "7c4df3d5",
        "outputId": "27b5d702-eb20-4cda-e578-080150c96fae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-33-25805d4bc91c>:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2630' max='2630' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2630/2630 02:44, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.502100</td>\n",
              "      <td>0.380110</td>\n",
              "      <td>0.820000</td>\n",
              "      <td>0.913000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.405000</td>\n",
              "      <td>0.339830</td>\n",
              "      <td>0.838000</td>\n",
              "      <td>0.931000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.355600</td>\n",
              "      <td>0.314382</td>\n",
              "      <td>0.858000</td>\n",
              "      <td>0.939000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.356500</td>\n",
              "      <td>0.348863</td>\n",
              "      <td>0.849000</td>\n",
              "      <td>0.946000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.352400</td>\n",
              "      <td>0.340203</td>\n",
              "      <td>0.862000</td>\n",
              "      <td>0.948000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.348700</td>\n",
              "      <td>0.291209</td>\n",
              "      <td>0.871000</td>\n",
              "      <td>0.950000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.335700</td>\n",
              "      <td>0.288819</td>\n",
              "      <td>0.876000</td>\n",
              "      <td>0.950000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.313100</td>\n",
              "      <td>0.289805</td>\n",
              "      <td>0.867000</td>\n",
              "      <td>0.950000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.312500</td>\n",
              "      <td>0.284702</td>\n",
              "      <td>0.873000</td>\n",
              "      <td>0.951000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.313700</td>\n",
              "      <td>0.289362</td>\n",
              "      <td>0.867000</td>\n",
              "      <td>0.951000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2630, training_loss=0.359555416324746, metrics={'train_runtime': 164.9048, 'train_samples_per_second': 127.346, 'train_steps_per_second': 15.949, 'total_flos': 706603239165360.0, 'train_loss': 0.359555416324746, 'epoch': 10.0})"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_data[\"train\"],\n",
        "    eval_dataset=tokenized_data[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf6b12cc",
      "metadata": {
        "id": "cf6b12cc"
      },
      "source": [
        "### Apply Model to Validation Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "ba1f2710",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ba1f2710",
        "outputId": "fb6dc1bc-9d9f-4e39-e046-0792269157d7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Accuracy': 0.891, 'AUC': 0.945}\n"
          ]
        }
      ],
      "source": [
        "# apply model to validation dataset\n",
        "predictions = trainer.predict(tokenized_data[\"validation\"])\n",
        "\n",
        "# Extract the logits and labels from the predictions object\n",
        "logits = predictions.predictions\n",
        "labels = predictions.label_ids\n",
        "\n",
        "# Use your compute_metrics function\n",
        "metrics = compute_metrics((logits, labels))\n",
        "print(metrics)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hzb2v9T7i2Tb"
      },
      "id": "Hzb2v9T7i2Tb",
      "execution_count": 34,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8c5b6addc8de445e8622702e50972d21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5936b77da88c4fefa0af273625670d1c",
              "IPY_MODEL_eb78fca1614a40cc8dbbed6866de8ef1",
              "IPY_MODEL_9412e28ad64d42c59df8d03fd9b654b4"
            ],
            "layout": "IPY_MODEL_aa67cf721f454cdea31f3ff9808e3414"
          }
        },
        "5936b77da88c4fefa0af273625670d1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e44e081ac7c9420790b487121e2b35f7",
            "placeholder": "​",
            "style": "IPY_MODEL_64cf21145cf94c1b87a9a2f4ab82f92f",
            "value": "Map: 100%"
          }
        },
        "eb78fca1614a40cc8dbbed6866de8ef1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c80d97bd202e4c96bcaca8b7e81d18d5",
            "max": 450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0f23040bdd594fdcb4b06794296fd0f3",
            "value": 450
          }
        },
        "9412e28ad64d42c59df8d03fd9b654b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7dd42acbf05f43e4b17e9bb3fecf30fe",
            "placeholder": "​",
            "style": "IPY_MODEL_6583ed437f684ad38a1d2d8039ab736d",
            "value": " 450/450 [00:00&lt;00:00, 6902.79 examples/s]"
          }
        },
        "aa67cf721f454cdea31f3ff9808e3414": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e44e081ac7c9420790b487121e2b35f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64cf21145cf94c1b87a9a2f4ab82f92f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c80d97bd202e4c96bcaca8b7e81d18d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f23040bdd594fdcb4b06794296fd0f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7dd42acbf05f43e4b17e9bb3fecf30fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6583ed437f684ad38a1d2d8039ab736d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}